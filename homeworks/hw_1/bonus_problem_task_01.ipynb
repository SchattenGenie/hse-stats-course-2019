{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import gamma, psi, polygamma\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maximum likelihood оптимизация\n",
    "\n",
    "Очень часто в машинном обучении и статистике возникает задача когда есть данные $X$, некоторое параметрическое распределение $p(x | \\theta)$ и желание найти параметры $\\theta$. \n",
    "\n",
    "Самые лучшие параметры это те которые минимизируют функцию правдоподобия: $\\mathcal{L}(X, \\theta)$, во многих случаях это можно сделать аналитически(почти для всех известных нам именных распределений).\n",
    "\n",
    "В случае если нет возможности посчитать аналитически MLE-оценки приходится обращаться к итеративным методам оптимизации. Один из самых популярных способов это градиентный спуск, который, формально решает следующую задачу:\n",
    "\n",
    "$$d \\theta = \\arg \\max \\mathcal{L}(X|\\theta + d \\theta), s.t. ||d\\theta|| < \\epsilon$$\n",
    "\n",
    "И результатом решения этой задачи является:\n",
    "\n",
    "$$d\\theta = \\frac{\\nabla_\\theta \\mathcal{L}}{||\\nabla_\\theta \\mathcal{L}||} \\epsilon$$\n",
    "\n",
    "Оптимально ли это? \n",
    "\n",
    "Мы ограничиваем наш шаг $||d\\theta||$ сферой радиусом $\\epsilon$ в евклидовом пространстве, но это не особо разумно. \n",
    "\n",
    "По этой причине мы бы хотели научиться решать следующую задачу:\n",
    "\n",
    "$$d \\theta = \\arg \\max \\mathcal{L}(X|\\theta + d \\theta), s.t. KL\\left( p(x| \\theta) || p(x| \\theta + d \\theta) \\right) < \\epsilon$$\n",
    "\n",
    "То есть мы хотели бы на каждом шаге оптимизации делать шаг на $\\epsilon$ по метрике KL, а не по метрике $L_2$.\n",
    "\n",
    "\n",
    "### KL дивергенция\n",
    "\n",
    "KL-дивергенция выглядит следующим образом:\n",
    "\n",
    "$$KL\\left(p(x|\\theta)||p(x|\\theta')\\right) = \\int p(x|\\theta) \\log \\frac{p(x|\\theta)}{p(x|\\theta')} dx $$\n",
    "\n",
    "А теперь зададимся вопросом: как нам оптимизировать параметры так чтобы спускаться с постоянной скоростью по метрике KL?\n",
    "\n",
    "Для этого расмотрим $\\mathrm{KL}\\left[ p_{\\theta} || p_{\\theta + d \\theta} \\right]$ - KL-дивергенцию от двух очень близких друг к другу распределений и разложим эту функцию по Тейлору при $d \\theta \\rightarrow 0$:\n",
    "\n",
    "$$\n",
    "\\mathrm{KL}\\left[ p_{\\theta} || p_{\\theta + d \\theta} \\right] \\approx \\mathrm{KL}\\left[ p_{\\theta} || p_{\\theta} \\right] + \\left( \\nabla_{\\theta'} \\mathrm{KL}\\left[ p_{\\theta} || p_{\\theta'} \\right]|_{\\theta' = \\theta} \\right)^T d\\theta + \\frac{1}{2} d \\theta^T \\left( \\nabla_{\\theta'}^2 \\mathrm{KL}\\left[ p_{\\theta} || p_{\\theta'} \\right] |_{\\theta' = \\theta} \\right) d \\theta\n",
    "$$\n",
    "\n",
    "Посчитаем второй член:\n",
    "\n",
    "$$\n",
    "\\nabla_{\\theta'} \\mathrm{KL}\\left(p(x|\\theta)||p(x|\\theta')\\right) |_{\\theta' = \\theta}  = - \\nabla_{\\theta'} \\mathrm{E}_{ p(x|\\theta)} \\log p(x|\\theta') |_{\\theta' = \\theta} = \\\\\n",
    "= \\int \\nabla \\log p(x|\\theta) p(x|\\theta) dx = 0\n",
    "$$\n",
    "\n",
    "\n",
    "Посчитаем второй член:\n",
    "\n",
    "А теперь возьмём вторую производную.\n",
    "\n",
    "$$\n",
    "\\nabla_{\\theta'}^2 \\mathrm{KL}\\left(p(x|\\theta)||p(x|\\theta')\\right)  = - \\int p(x|\\theta) \\nabla_{\\theta'}^2 \\log p(x | \\theta') dx\n",
    "$$\n",
    "\n",
    "Вторая производная по вектору параметров от $\\log p(x|\\theta')$ это матрица Гессе. \n",
    "\n",
    "Если расмотреть её в точке $\\theta=\\theta'$, то результат будет следующий(без вывода):\n",
    "\n",
    "$$\n",
    "\\nabla_{\\theta'}^2 \\mathrm{KL}\\left(p(x|\\theta)||p(x|\\theta')\\right) = - E \\left[ \\mathrm{H}_{\\log p(x | \\theta)} \\right]\n",
    "$$\n",
    "\n",
    "\n",
    "###### Теперь мы готовы вернуться к исходному разложению:\n",
    "\n",
    "$$\n",
    "\\mathrm{KL}\\left[ p_{\\theta} || p_{\\theta + d \\theta} \\right] \\approx - \\frac{1}{2} d \\theta^T E \\left[ \\mathrm{H}_{\\log p(x | \\theta)} \\right] d \\theta \n",
    "$$\n",
    "\n",
    "\n",
    "##### Ещё одно усилие :)\n",
    "\n",
    "Теперь мы готовы решить изначальную задачу:\n",
    "\n",
    "$$d \\theta = \\arg \\max \\mathcal{L}(X|\\theta + d \\theta), s.t. KL\\left( p(x| \\theta) || p(x| \\theta + d \\theta) \\right) < \\epsilon$$\n",
    "\n",
    "Перепишем её через теорему ККТ:\n",
    "\n",
    "$$d \\theta = \\arg \\max \\mathcal{L}(X|\\theta + d \\theta) + \\lambda \\left( \\mathrm{KL}\\left[ p_{\\theta} || p_{\\theta + d \\theta} \\right]  - \\epsilon \\right)$$\n",
    "\n",
    "Разложим log-likelihood до линейного члена, а KL до квадратичного:\n",
    "\n",
    "$$\n",
    "d \\theta \\approx \\arg \\max  \\mathcal{L}(\\theta) + \\nabla_\\theta^T d \\theta -  \\frac{1}{2} \\lambda d \\theta^T E \\left[ \\mathrm{H}_{\\log p(x | \\theta)} \\right] d \\theta  - \\lambda \\epsilon\n",
    "$$\n",
    "\n",
    "Возьмём производную по $d \\theta$ от правой части и приравняем нулю:\n",
    "\n",
    "$$\n",
    "0 = \\nabla_\\theta \\mathcal{L} - \\lambda E \\left[ \\mathrm{H}_{\\log p(x | \\theta)} \\right] d \\theta\n",
    "$$\n",
    "\n",
    "$$\n",
    "d \\theta = \\frac{1}{\\lambda} E \\left[ \\mathrm{H}_{\\log p(x | \\theta)} \\right]^{-1} \\nabla_\\theta \\mathcal{L}\n",
    "$$\n",
    "\n",
    "\n",
    "### Связь KL-дивергенции и матрицы Фишера\n",
    "\n",
    "Гессиан log-likelihood функции это одна из форм записи матрицы Фишера:\n",
    "\n",
    "$$I_n = - E \\left[ \\mathrm{H}_{\\log p(x | \\theta)} \\right]$$\n",
    "\n",
    "Таким образом, матрица Фишера, гессиан log-likelihood функции и гессиан KL-дивергенции это одно и тоже.\n",
    "\n",
    "### Расчёт матрицы Фишера\n",
    "\n",
    "Более удобный способ расчёта матрицы Фишера:\n",
    "\n",
    "$$I_n = E\\left[ \\left( \\frac{\\partial \\log p(\\vec{x}|\\vec{\\theta})}{\\partial \\vec{\\theta}} \\right) \n",
    "\\left( \\frac{\\partial \\log p(\\vec{x}|\\vec{\\theta})}{\\partial \\vec{\\theta}}\\right)^T  \\right]$$\n",
    "\n",
    "\n",
    "Производную мы посчитали выше. А как нам посчитать матожидание?\n",
    "\n",
    "Усреднение по элементам выборки есть приближение среднего,поэтому самый простой способ это посчитать матрицу Фишера для каждого элемента нашей выборки и усреднить."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задача\n",
    "\n",
    "\n",
    "### 0. Вступление\n",
    "\n",
    "Давайте вспомним задачу про генотипы и относительную приспособленность.\n",
    "\n",
    "\"Относительную приспособленность\" определяют среднее количество выживших представителей одного генотипа к среднему количеству выживших представителей другого генотипа. \n",
    "\n",
    "Eyre-Walker (2006) ( https://www.ncbi.nlm.nih.gov/pubmed/16547091 ) предположили, что функция преспособленности принадлежит семейству гамма-распределений случайных величин. \n",
    "\n",
    "Они проверили своё предположение для популяций людей с мутацией `deleterious amino acid`. \n",
    "\n",
    "Они получили следующие оценки на параметры гамма-распределения:\n",
    " \n",
    "$$\\hat{\\alpha} = 0.23,~~~ \\hat{\\beta} = 5.35$$\n",
    "\n",
    "$$\\Gamma(x | \\alpha, \\beta) = \\frac{\\beta^\\alpha}{\\Gamma(\\alpha)} x^{\\alpha - 1} \\exp(- \\beta x)$$\n",
    "\n",
    "### 1. Завязка сюжета и actual task\n",
    "\n",
    "На семинаре мы забили на непосредственную оптимизацию нашей функции и использовали `.fit`-метод, который предоставлял интерфейс в `scipy`-модуле.\n",
    "\n",
    "Теперь мы попробуем сами прооптимизировать вот это вот всё с помощью градиентного спуска и натурального градиентного спуска.\n",
    "\n",
    "А так же исследуем как введение априорных распределений влияет на результат работы алгоритма.\n",
    "\n",
    "### 2. Подробное описание задания\n",
    "\n",
    "1. Выпишите производные по $\\alpha, \\beta$ для логарифма правдоподобия гамма-распределения($\\Gamma(x | \\alpha, \\beta)$);\n",
    "2. Выпишите матрицу Фишера для гамма-распределения;\n",
    "3. (1 балл) Реализуйте градиентный спуск и натуральный градиентный спуск и сравните финальное качество и скорость сходимости(i.e. постройте кривые зависимости логарифма правдоподобия от номера итерации).\n",
    "    1. При решении п. 2 и п. 3 полезно почитать главу 9 отсюда: http://www.sherrytowers.com/mle_introduction.pdf\n",
    "4. Придумайте приорное распределение на $\\alpha$, $\\beta$: $p(\\alpha, \\beta)$. Во-первых, подумайте(и напишите!) какой биологический смысл эти параметры несут. Используя своё понимание, придумайте подходящее априорное распределения.\n",
    "5. Выведите самую неинформативную априорную вероятность Джеффриса для гамма-распределения($p(\\alpha, \\beta) = \\sqrt{|I(\\alpha, \\beta)|}$): https://ru.wikipedia.org/wiki/Априорная_вероятность_Джеффриса\n",
    "    \n",
    "    Из названия следует, что эта априорная вероятность является самой неинформативной(спс кэп), например, для $\\mu$ в $\\mathcal{N}(x | \\mu, \\sigma^2)$ априорной вероятностью Джеффриса будет равномерное распределение на всей числовой прямой.\n",
    "    1. Здесь вам пригодится матрица Фишера, которую вы посчитали в п. 2\n",
    "6. (1 балл) Выпишите производные по $\\alpha, \\beta$ и матрицу Фишера для распределений: $p(\\alpha, \\beta | x) = \n",
    "\\frac{\\Gamma(x | \\alpha, \\beta) p(\\alpha, \\beta)}{p(x)}$ с априорным распределением выбранным вами и с априорным распределением Джеффриса.\n",
    "7. Примените алгоритмы градиентного спуска и натурального градиентного спуска из п. 3 для оценки параметров $\\alpha, \\beta$ с вашей приорой и с приорой Джеффриса. \n",
    "8. (1 балл) В итоге у вас будет 4 графика сходимости log-likelihood от номера итераций. \n",
    "\n",
    "    К каким $\\alpha$ и $\\beta$ сошёлся алгоритм? Какие выводы вы можете сделать?\n",
    "    \n",
    "    Чем больше выводов и наблюдений вы сделаете -- тем лучше :)\n",
    "    \n",
    "    При экспериментах попробуйте разные инициализации $\\alpha$ и $\\beta$ и разные learning rates. Посмотрите к чему приводит их вариация.\n",
    "    \n",
    "\n",
    "    \n",
    "### 3. Заготовки кода\n",
    "\n",
    "(Вы можете их как использовать, так и не использовать)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GammaDistributionOracle:\n",
    "    def __init__(self, a, b):\n",
    "        self._a = a\n",
    "        self._b = b\n",
    "        \n",
    "    def update_parameters(self, a, b):\n",
    "        self._a = a\n",
    "        self._b = b\n",
    "    \n",
    "    def p(self, x):\n",
    "        \"\"\"\n",
    "        Probability to observe sample x\n",
    "        \"\"\"\n",
    "        return (np.power(self._b, self._a) / gamma(alpha)) * x**(self._a - 1) * np.exp(-self._b * x)\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        return self.p(x=x)\n",
    "    \n",
    "    def log_p(self, x):\n",
    "        \"\"\"\n",
    "        Log-probability to observe sample x\n",
    "        \"\"\"\n",
    "        NotImplementedError('log_p is not implemented')\n",
    "        \n",
    "    def grad(self, x):\n",
    "        \"\"\"\n",
    "        Derivative of log-probability [\\alpha, \\beta] at x\n",
    "        \"\"\"\n",
    "        NotImplementedError('grad is not implemented')\n",
    "    \n",
    "    def fisher_matrix(self):\n",
    "        \"\"\"\n",
    "        Fisher matrix for Gamma distribution\n",
    "        \"\"\"\n",
    "        NotImplementedError('fisher_matrix is not implemented')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PriorOracle:\n",
    "    def __init__(self, a, b):\n",
    "        self._a = a\n",
    "        self._b = b\n",
    "        \n",
    "    def update_parameters(self, a, b):\n",
    "        self._a = a\n",
    "        self._b = b\n",
    "    \n",
    "    def p(self):\n",
    "        \"\"\"\n",
    "        Probability\n",
    "        \"\"\"\n",
    "        raise NotImplementedError('p is not implemented')\n",
    "    \n",
    "    def __call__(self):\n",
    "        return self.p()\n",
    "    \n",
    "    def log_p(self):\n",
    "        \"\"\"\n",
    "        Log-probability to observe sample x\n",
    "        \"\"\"\n",
    "        raise NotImplementedError('log_p is not implemented')\n",
    "        \n",
    "    def grad(self):\n",
    "        \"\"\"\n",
    "        Derivative of log-probability [\\alpha, \\beta] at x\n",
    "        \"\"\"\n",
    "        raise NotImplementedError('grad is not implemented')\n",
    "    \n",
    "    def fisher_matrix(self):\n",
    "        \"\"\"\n",
    "        Fisher matrix for Gamma distribution\n",
    "        \"\"\"\n",
    "        raise NotImplementedError('fisher_matrix is not implemented')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "def gradient_descent(X, oracle, prior=None, epochs=100, lr=1e-3):\n",
    "    \"\"\"\n",
    "    Perfoms simple gradient descent with known oracle and prior\n",
    "    \"\"\"\n",
    "    history = defaultdict(list)\n",
    "    for epoch in range(epochs):\n",
    "        raise NotImplementedError('Gradient descent is not implemented')\n",
    "        gradient = ...\n",
    "        if prior: \n",
    "            gradient += ...\n",
    "        a = ...\n",
    "        b = ...\n",
    "        \n",
    "        # update parameters of oracle\n",
    "        oracle.update_parameters(a=a, b=b)\n",
    "        # update parameters of prior\n",
    "        if prior: prior.update_parameters(a=a, b=b)\n",
    "        history['log-likelihood'].append(oracle.log_p(X).mean())\n",
    "        if prior: history['log-prior'].append(prior.log_p())\n",
    "        history['a'].append(a)\n",
    "        history['b'].append(b)\n",
    "        \n",
    "    return history\n",
    "\n",
    "def natural_gradient_descent(X, oracle, prior=None, epochs=100, lr=1e-3):\n",
    "    \"\"\"\n",
    "    Perfoms simple gradient descent with known oracle and prior\n",
    "    \"\"\"\n",
    "    history = defaultdict(list)\n",
    "    for epoch in range(epochs):\n",
    "        NotImplementedError('Natural gradient descent is not implemented')\n",
    "        gradient = ...\n",
    "        fisher_matrix = ...\n",
    "        if prior: \n",
    "            gradient = ...\n",
    "            fisher_matrix = ...\n",
    "        gradient = ...\n",
    "        a = ...\n",
    "        b = ...\n",
    "        \n",
    "        # update parameters of oracle\n",
    "        oracle.update_parameters(a=a, b=b)\n",
    "        # update parameters of prior\n",
    "        if prior: prior.update_parameters(a=a, b=b)\n",
    "        history['log-likelihood'].append(oracle.log_p(X).mean())\n",
    "        if prior: history['log-prior'].append(prior.log_p())\n",
    "        history['a'].append(a)\n",
    "        history['b'].append(b)\n",
    "        \n",
    "    history['a'] = np.array(history['a'])\n",
    "    history['b'] = np.array(history['b'])\n",
    "    history['log-likelihood'] = np.array(history['log-likelihood'])\n",
    "    if \"log-prior\" in history:\n",
    "        history['log-prior'] = np.array(history['log-prior'])\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotter(history):\n",
    "    f, ax = plt.subplots(1, 3, figsize=(16, 6))\n",
    "    ax[0].plot(history['log-likelihood'], label='Log-likelihood')\n",
    "    if \"log-prior\" in history:\n",
    "        ax[0].plot(history['log-prior'], label='Log-prior')\n",
    "        ax[0].plot(history['log-likelihood'] + history['log-prior'], label='Log-likelihood')\n",
    "    ax[1].plot(history['a'], label=r'$\\alpha$')\n",
    "    ax[2].plot(history['b'], label=r'$\\beta$')\n",
    "    plt.legend()\n",
    "    plt.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Пайплайн запуска"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import gamma as gamma_dist\n",
    "np.random.seed(1337)\n",
    "alpha = 0.23\n",
    "beta = 5.35\n",
    "# генерируем выборку\n",
    "X = gamma_dist.rvs(scale=1 / beta, a=alpha, size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_init = 1\n",
    "beta_init = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oracle = GammaDistributionOracle(a=alpha_init, b=beta_init)\n",
    "prior = PriorOracle(a=alpha_init, b=beta_init) # prior = None, если не используется приора\n",
    "history = gradient_descent(oracle=oracle, X=X, prior=prior, epochs=10000)\n",
    "plotter(history=history)\n",
    "print(history['log-likelihood'][-1], history['a'][-1], history['b'][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oracle = GammaDistributionOracle(a=alpha_init, b=beta_init)\n",
    "prior = PriorOracle(a=alpha_init, b=beta_init) # prior = None, если не используется приора\n",
    "history = natural_gradient_descent(oracle=oracle, prior=prior, X=X, epochs=10000) \n",
    "plotter(history=history)\n",
    "print(history['log-likelihood'][-1], history['a'][-1], history['b'][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
